


					MLFlow Project Report on Titanic Dataset
					----------------------------------------


Steps:

1.	Install MLFlow and required libraries.

	Run the following commands in terminal:
	pip install mlflow
        	pip install scikit-learn

2.	Load, preprocess the data and perform EDA.

 	Preprocessing and EDA have been documented in the following file:
		Titantic_preprocessing.ipynb

	(Link : https://github.com/h-mehta/SE-for-DS/blob/main/Data%20Engineering/MLFlow/titanic/Titantic_preprocessing.ipynb )

3.	Save the preprocessed data so it can be directly read-in by the .py file that contains code to develop model on this pre-processed data.

	Data after pre-processing: titanic_processed_data.csv

	(Link: https://github.com/h-mehta/SE-for-DS/blob/main/Data%20Engineering/MLFlow/titanic/titanic_processed_data.csv )

4.	Train the classification model and log the parameters and metrics after each run using MLFlow.

	Code in file: titanic_code.py 

	(Link: https://github.com/h-mehta/SE-for-DS/blob/main/Data%20Engineering/MLFlow/titanic/titanic_code.py )  

5.	Can create custom logs also apart from those generated by MLFlow:

	The custom logs are recoding parameters (n_estimators, learning rate, max depth) and metrics (Accuracy, Precision, recall, F1) successfully.


6.	Write bash script to run the model for various combinations of hyperparamters:

	(Refer: https://github.com/h-mehta/SE-for-DS/blob/main/Data%20Engineering/MLFlow/titanic/grid_search.sh )

7.	Run the model for different values of hyperparameters – MLFlow keeps a log of hyperparameters and metrics for each run – and then run MLFlow UI:

 	After running the for 250+ combinations of hyperparameters, we can see that the best accuracy is achieved with the following hyperparameters:
	
	Learning rate: 0.1
	Max depth: 5
	Estimators: 400
	
	Accuracy: 82.7%
	F1: 0.786
	Precision: 0.803
	Recall: 0.77



